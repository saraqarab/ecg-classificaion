{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG_Clasiification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFbv-TDsBXlL"
      },
      "source": [
        "import numpy\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Conv1D, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras import backend as K\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGL_h17YB4RW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d1fc12d0-96aa-4d39-c076-361186832514"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsfX_es9BbQl"
      },
      "source": [
        "number_of_classes = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z6I00XsBkiW"
      },
      "source": [
        "def change(x): \n",
        "    answer = np.zeros((np.shape(x)[0]))\n",
        "    for i in range(np.shape(x)[0]):\n",
        "        max_value = max(x[i, :])\n",
        "        max_index = list(x[i, :]).index(max_value)\n",
        "        answer[i] = max_index\n",
        "    return answer.astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OPTaffVBsl-"
      },
      "source": [
        "if sys.argv[1] == 'cinc':\n",
        "    #Loading of .mat files from training directory. Only 9000 time steps from every ECG file is loaded\n",
        "    mypath = '/content/drive/My Drive/fastai-v3/data/ECG/mitbih-database/mitbih_database/'\n",
        "    onlyfiles = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and f[0] == 'A')]\n",
        "    bats = [f for f in onlyfiles if f[7] == 'm']\n",
        "    mats = [f for f in bats if (np.shape(sio.loadmat(mypath + f)['val'])[1] >= 9000)] #Choic of only 9k time steps\n",
        "    check = np.shape(sio.loadmat(mypath + mats[0])['val'])[1]\n",
        "    X = np.zeros((len(mats), check))\n",
        "    for i in range(len(mats)):\n",
        "        X[i, :] = sio.loadmat(mypath + mats[i])['val'][0,:9000]\n",
        "        target_train = np.zeros((len(mats), 1))\n",
        "    Train_data = pd.read_csv(mypath + 'REFERENCE.csv', sep=',', header=None, names=None)\n",
        "    for i in range(len(mats)):\n",
        "        if Train_data.loc[Train_data[0] == mats[i][:6], 1].values == 'N':\n",
        "            target_train[i] = 0\n",
        "        elif Train_data.loc[Train_data[0] == mats[i][:6], 1].values == 'A':\n",
        "            target_train[i] = 1\n",
        "        elif Train_data.loc[Train_data[0] == mats[i][:6], 1].values == 'O':\n",
        "            target_train[i] = 2\n",
        "        else:\n",
        "            target_train[i] = 3\n",
        "\n",
        "    Label_set = np.zeros((len(mats), number_of_classes))\n",
        "    for i in range(np.shape(target_train)[0]):\n",
        "        dummy = np.zeros((number_of_classes))\n",
        "        dummy[int(target_train[i])] = 1\n",
        "        Label_set[i, :] = dummy\n",
        "        \n",
        "elif sys.argv[1] == 'mit':\n",
        "    print('In proces...')\n",
        "    sys.exit()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXZ6aZvqDQuN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "80de2fb1-b184-4aea-aa11-048f92c7a77e"
      },
      "source": [
        "mypath = '/content/drive/My Drive/fastai-v3/data/ECG/training2017/'\n",
        "onlyfiles = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and f[0] == 'A')]\n",
        "bats = [f for f in onlyfiles if f[7] == 'm']\n",
        "mats = [f for f in bats if (np.shape(sio.loadmat(mypath + f)['val'])[1] >= 9000)]\n",
        "Label_set = np.zeros((len(mats), number_of_classes))\n",
        "check = np.shape(sio.loadmat(mypath + mats[0])['val'])[1]\n",
        "shape = (len(mats),check)\n",
        "X = np.zeros((shape))\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(X)\n",
        "train_len = 0.8 #Choice of training size\n",
        "X_train = X[:int(train_len*len(mats)), :]\n",
        "Y_train = Label_set[:int(train_len*len(mats)), :]\n",
        "X_val = X[int(train_len*len(mats)):, :]\n",
        "Y_val = Label_set[int(train_len*len(mats)):, :]\n",
        "\n",
        "# reshape input to be [samples, tensor shape (30 x 300)]\n",
        "n = 20\n",
        "m = 450\n",
        "c = 1 #number of channels\n",
        "\n",
        "X_train = numpy.reshape(X_train, (X_train.shape[0], n, m, c))\n",
        "#X_val = numpy.reshape(X_val, (X_val.shape[0], n, m, c))\n",
        "image_size = (n, m, c)\n",
        "\n",
        "batch_size = 32\n",
        "model = Sequential()\n",
        "#model.load_weights('my_model_weights.h5')\n",
        "#64 conv\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKCUpLY4K4T_"
      },
      "source": [
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=image_size, padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "#128 conv\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same' ))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# #256 conv\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# #512 conv\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "#Dense part\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "#Callbacks and accuracy calculation\n",
        "#early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=50, verbose=1, mode='auto')\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(filepath=\"Keras_models/weights.{epoch:02d}-{val_acc:.2f}.hdf5\", monitor='val_loss', save_weights_only=False, period=1, verbose=1, save_best_only=False)\n",
        "model.fit(X_train, Y_train, epochs=250, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=2, shuffle=False, callbacks=[checkpointer])\n",
        "model.save('Keras_models/my_model_' + str(i) + '_' + str(j) + '_' + str() + '.h5')\n",
        "predictions = model.predict(X_val)\n",
        "score = accuracy_score(change(Y_val), change(predictions))\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}